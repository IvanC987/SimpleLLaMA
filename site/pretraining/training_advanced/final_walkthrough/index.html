
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../ckpt_and_eval/">
      
      
        <link rel="next" href="../../../sft/overview/">
      
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.18">
    
    
      
        <title>Final Walkthrough - SimpleLLaMA Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#training-script-walkthrough" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="SimpleLLaMA Documentation" class="md-header__button md-logo" aria-label="SimpleLLaMA Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SimpleLLaMA Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Final Walkthrough
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="SimpleLLaMA Documentation" class="md-nav__button md-logo" aria-label="SimpleLLaMA Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    SimpleLLaMA Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Pretraining
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Pretraining
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset Preparation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tokenization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Tokenization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization/algorithms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algorithms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization/examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../tokenization/project/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Project Usage
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Model Architecture
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Model Architecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/attention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/normalization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Normalization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/feedforward/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FeedForward
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/decoder_block/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Layer Block
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../model_architecture/end_to_end/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    End To End
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training Process (Beginner)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Training Process (Beginner)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_beginner/introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_beginner/model_config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Configurations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_beginner/dataset_and_batching/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset and Batching
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_beginner/scheduler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Scheduler
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../training_beginner/training_loop/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Training Loop
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" checked>
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training Process (Advanced)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            Training Process (Advanced)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../recap/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Basics Recap
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Optimizer Details
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../loss_function/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cross Entropy Loss
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradient_accumulation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gradient Accumulation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributed Data Parallel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../throughput_optimizations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Throughput Optimizations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ckpt_and_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Checkpointing and Evaluations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Final Walkthrough
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Final Walkthrough
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#initial-setup-and-imports" class="md-nav__link">
    <span class="md-ellipsis">
      Initial Setup and Imports
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed Training Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducibility-and-performance-settings" class="md-nav__link">
    <span class="md-ellipsis">
      Reproducibility and Performance Settings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration Loading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training-adjustments" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed Training Adjustments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logging-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Logging Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-calculations" class="md-nav__link">
    <span class="md-ellipsis">
      Training Calculations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-and-data-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Model and Data Initialization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizer-and-scheduler-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer and Scheduler Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoint-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoint Loading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-compilation-and-ddp-wrapping" class="md-nav__link">
    <span class="md-ellipsis">
      Model Compilation and DDP Wrapping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop Initialization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#main-training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Main Training Loop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-accumulation-and-backward-pass" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Accumulation and Backward Pass
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizer-step" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer Step
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoint-saving" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoint Saving
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-and-logging" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation and Logging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation-samples" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation Samples
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      Cleanup
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Supervised Fine-Tuning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Supervised Fine-Tuning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sft/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sft/dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sft/prompt_formatting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prompt Formatting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sft/utils/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Utilities
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../sft/finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Finetuning Process
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    RLHF
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            RLHF
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rlhf/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../rlhf/methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Methods
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Misc
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Misc
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../misc/benchmarking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../misc/inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Inference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../misc/notes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Notes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Custom Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Custom Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../custom_training/pretraining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pretraining
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../custom_training/sft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised Fine Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../custom_training/rlhf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RLHF
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#initial-setup-and-imports" class="md-nav__link">
    <span class="md-ellipsis">
      Initial Setup and Imports
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed Training Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#reproducibility-and-performance-settings" class="md-nav__link">
    <span class="md-ellipsis">
      Reproducibility and Performance Settings
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#configuration-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Configuration Loading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#distributed-training-adjustments" class="md-nav__link">
    <span class="md-ellipsis">
      Distributed Training Adjustments
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logging-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Logging Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-calculations" class="md-nav__link">
    <span class="md-ellipsis">
      Training Calculations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-and-data-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Model and Data Initialization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizer-and-scheduler-setup" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer and Scheduler Setup
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoint-loading" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoint Loading
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-compilation-and-ddp-wrapping" class="md-nav__link">
    <span class="md-ellipsis">
      Model Compilation and DDP Wrapping
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#training-loop-initialization" class="md-nav__link">
    <span class="md-ellipsis">
      Training Loop Initialization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#main-training-loop" class="md-nav__link">
    <span class="md-ellipsis">
      Main Training Loop
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#gradient-accumulation-and-backward-pass" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Accumulation and Backward Pass
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimizer-step" class="md-nav__link">
    <span class="md-ellipsis">
      Optimizer Step
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#checkpoint-saving" class="md-nav__link">
    <span class="md-ellipsis">
      Checkpoint Saving
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-and-logging" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation and Logging
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-generation-samples" class="md-nav__link">
    <span class="md-ellipsis">
      Text Generation Samples
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cleanup" class="md-nav__link">
    <span class="md-ellipsis">
      Cleanup
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="training-script-walkthrough">Training Script Walkthrough</h1>
<p>This final piece of documentation in the training guide section provides a sequential walkthrough of the LLM training script, explaining each major section and how everything connects.</p>
<hr />
<h2 id="initial-setup-and-imports">Initial Setup and Imports</h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span> <span class="k">as</span> <span class="n">DDP</span>
<span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">init_process_group</span><span class="p">,</span> <span class="n">destroy_process_group</span>
<span class="kn">from</span> <span class="nn">tokenizers</span> <span class="kn">import</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">decoders</span>

<span class="kn">from</span> <span class="nn">simple_llama.pretraining.llama_transformer</span> <span class="kn">import</span> <span class="n">LLaMaTransformer</span>
<span class="kn">from</span> <span class="nn">simple_llama.pretraining.dataset_loader</span> <span class="kn">import</span> <span class="n">DatasetLoader</span>
<span class="kn">from</span> <span class="nn">simple_llama.pretraining.lr_scheduler</span> <span class="kn">import</span> <span class="n">Scheduler</span>
<span class="kn">from</span> <span class="nn">simple_llama.pretraining.utils</span> <span class="kn">import</span> <span class="n">load_checkpoint</span><span class="p">,</span> <span class="n">few_shot_prompts</span><span class="p">,</span> <span class="n">check_log_file_existence</span>
<span class="kn">from</span> <span class="nn">simple_llama.pretraining.config</span> <span class="kn">import</span> <span class="n">TrainingConfig</span>
</code></pre></div>
<p><strong>Key imports:</strong></p>
<ul>
<li><code>torch.distributed</code>: For multi-GPU training support  </li>
<li><code>tokenizers</code>: Hugging Face tokenizer for text processing  </li>
<li>Custom modules: Model architecture, data loading, and utilities  </li>
</ul>
<hr />
<h2 id="distributed-training-setup">Distributed Training Setup</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># To run, use `torchrun --standalone --nproc_per_node=8 train.py`</span>
<span class="c1"># Set global variables for DDP</span>
<span class="n">ddp</span> <span class="o">=</span> <span class="s2">&quot;RANK&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span> <span class="ow">and</span> <span class="s2">&quot;WORLD_SIZE&quot;</span> <span class="ow">in</span> <span class="n">os</span><span class="o">.</span><span class="n">environ</span>
<span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">(),</span> <span class="s2">&quot;Should have cuda available if using DDP!&quot;</span>
    <span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>  <span class="c1"># Initialize the distributed communication backend</span>
    <span class="n">ddp_rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;RANK&quot;</span><span class="p">])</span>
    <span class="c1"># Assuming this is single-node multi-GPU setup, so I&#39;m not using local_rank</span>
    <span class="n">ddp_world_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;WORLD_SIZE&quot;</span><span class="p">])</span>
    <span class="n">device</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;cuda:</span><span class="si">{</span><span class="n">ddp_rank</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="n">ddp_rank</span> <span class="o">==</span> <span class="mi">0</span>
<span class="k">else</span><span class="p">:</span>  <span class="c1"># Non-Distributed setup. Either CPU or single GPU</span>
    <span class="n">ddp_rank</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">ddp_world_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">master_process</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">device</span> <span class="o">=</span> <span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Currently using </span><span class="si">{</span><span class="n">device</span><span class="si">=}</span>
<span class="s2">&quot;)</span>
</code></pre></div>
<p><strong>What this does:</strong></p>
<ul>
<li>Checks if we're running in a distributed environment by looking for RANK and WORLD_SIZE environment variables (Automatically set by <code>torchrun</code> when used)</li>
<li>Initializes the process group with NCCL backend for GPU communication  </li>
<li>Sets device to the appropriate GPU for each process  </li>
<li>Designates rank 0 as the <code>master_process</code> for logging and checkpointing  </li>
</ul>
<hr />
<h2 id="reproducibility-and-performance-settings">Reproducibility and Performance Settings</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># Manual seeding for reproducibility testings</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">89</span>
<span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

<span class="c1"># Setting to &#39;high&#39; uses TF32 rather than FP32, which makes the training process faster (varies on machines)</span>
<span class="c1"># Can set to &#39;medium&#39; for even faster training, though will be loss in performance</span>
<span class="n">torch</span><span class="o">.</span><span class="n">set_float32_matmul_precision</span><span class="p">(</span><span class="s2">&quot;high&quot;</span><span class="p">)</span>
</code></pre></div>
<p>Using the same random seeds ensure training is reproducible across runs and TF32 precision provides speedup on NVIDIA Ampere+ GPUs while maintaining accuracy  </p>
<hr />
<h2 id="configuration-loading">Configuration Loading</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># Hyperparameters</span>
<span class="c1"># --------------------------------------</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">TrainingConfig</span><span class="p">()</span>

<span class="c1"># Unpack values from config for convenience</span>
<span class="n">enable_compilation</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">enable_compilation</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">batch_size</span>
<span class="n">max_seq_len</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_seq_len</span>

<span class="n">eval_interval</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">eval_interval</span>
<span class="n">training_tokens</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">training_tokens</span>

<span class="n">warmup_iterations</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">warmup_iterations</span>
<span class="n">max_lr</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">max_lr</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">min_lr</span>
<span class="n">beta1</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">beta1</span>
<span class="n">beta2</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">beta2</span>
<span class="n">weight_decay</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">weight_decay</span>

<span class="n">grad_accum_steps</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">grad_accum_steps</span>
<span class="n">load_ckpt</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">load_ckpt</span>
<span class="n">token_ckpt</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">token_ckpt</span>
<span class="n">use_prev_scheduler</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">use_prev_scheduler</span>

<span class="n">log_file</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">log_file</span>
<span class="n">model_gen_multiplier</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">model_gen_multiplier</span>

<span class="n">eval_interval</span> <span class="o">*=</span> <span class="n">grad_accum_steps</span>  <span class="c1"># So evaluate model after eval_interval number of gradient updates</span>
<span class="c1"># --------------------------------------</span>
</code></pre></div>
<p><strong>Key configuration values for our 1.3B model:</strong></p>
<ul>
<li><code>batch_size = 4</code> sequences per GPU  </li>
<li><code>max_seq_len = 2048</code> tokens per sequence  </li>
<li><code>training_tokens = 45,000,000,000</code> (45B tokens)  </li>
<li><code>grad_accum_steps = 64</code> (for effective batch size of 524,288 tokens)  </li>
</ul>
<hr />
<h2 id="distributed-training-adjustments">Distributed Training Adjustments</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># Need to make sure gradient accumulation step is evenly divisible by # GPUs</span>
<span class="k">assert</span> <span class="n">grad_accum_steps</span> <span class="o">%</span> <span class="n">ddp_world_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">grad_accum_steps</span><span class="si">=}</span><span class="s2"> % </span><span class="si">{</span><span class="n">ddp_world_size</span><span class="si">=}</span><span class="s2"> != 0</span><span class="se">\n</span><span class="s2">&quot;</span>
                                                <span class="sa">f</span><span class="s2">&quot;Please adjust &#39;tokens_per_update&#39; in config file accordingly!&quot;</span><span class="p">)</span>

<span class="n">grad_accum_steps</span> <span class="o">=</span> <span class="n">grad_accum_steps</span> <span class="o">//</span> <span class="n">ddp_world_size</span>

<span class="c1"># Do the same for eval interval</span>
<span class="k">assert</span> <span class="n">eval_interval</span> <span class="o">%</span> <span class="n">ddp_world_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">eval_interval</span><span class="si">=}</span><span class="s2"> % </span><span class="si">{</span><span class="n">ddp_world_size</span><span class="si">=}</span><span class="s2"> != 0</span><span class="se">\n</span><span class="s2">&quot;</span>
                                             <span class="sa">f</span><span class="s2">&quot;Please adjust &#39;eval_interval&#39; in config file accordingly!&quot;</span><span class="p">)</span>

<span class="n">eval_interval</span> <span class="o">=</span> <span class="n">eval_interval</span> <span class="o">//</span> <span class="n">ddp_world_size</span>
</code></pre></div>
<p>These adjustments are needed in DDP because since each GPU accumulates gradients independently, we need to ensure all GPUs perform the same number of accumulation steps and evaluation intervals must be synchronized across processes.  </p>
<p>Note the <code>grad_accum_steps</code> update. 
If <code>ddp_world_size</code> is 1, meaning single GPU training, then <code>grad_accum_steps</code> remains the same. However, if <code>ddp_world_size</code> is 8, meaning training is being parallized across 8 GPUs, then <code>grad_accum_steps</code> would be reduced by 1/8.  </p>
<p>For the remainder of this walkthrough, we'll assume <code>ddp_world_size=8</code> and <code>grad_accum_steps=8</code></p>
<hr />
<h2 id="logging-setup">Logging Setup</h2>
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>  <span class="c1"># Check if log_file already exists and deal with it accordingly</span>
    <span class="n">log_file</span> <span class="o">=</span> <span class="n">check_log_file_existence</span><span class="p">(</span><span class="n">log_file</span><span class="p">,</span> <span class="n">ddp</span><span class="p">)</span>

<span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">log_file</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="s2">&quot;progress (%)&quot;</span><span class="p">,</span> <span class="s2">&quot;Training Loss&quot;</span><span class="p">,</span> <span class="s2">&quot;Perplexity&quot;</span><span class="p">,</span> <span class="s2">&quot;Learning Rate&quot;</span><span class="p">,</span> <span class="s2">&quot;L2 Norm&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Tokens Processed (Current- In Millions)&quot;</span><span class="p">,</span> <span class="s2">&quot;Tokens Processed (Total- In Millions)&quot;</span><span class="p">,</span>
                   <span class="s2">&quot;Tokens Per Second&quot;</span><span class="p">,</span> <span class="s2">&quot;Time Per Evaluation&quot;</span><span class="p">]</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">columns</span><span class="p">))</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<p><strong>Logging strategy:</strong></p>
<ul>
<li>Only the master process handles file I/O to avoid conflicts  </li>
<li>CSV format for easy analysis and plotting  </li>
<li>Various metrics to monitor training progress  </li>
</ul>
<hr />
<h2 id="training-calculations">Training Calculations</h2>
<div class="highlight"><pre><span></span><code><span class="n">tokens_per_step</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">max_seq_len</span> <span class="o">*</span> <span class="n">ddp_world_size</span>
<span class="n">tokens_per_opt_step</span> <span class="o">=</span> <span class="n">tokens_per_step</span> <span class="o">*</span> <span class="n">grad_accum_steps</span>   <span class="c1"># How many tokens to process before optimization step</span>
<span class="n">train_iterations</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">training_tokens</span> <span class="o">//</span> <span class="n">tokens_per_step</span><span class="p">)</span>
<span class="n">optimization_steps</span> <span class="o">=</span> <span class="n">train_iterations</span> <span class="o">//</span> <span class="n">grad_accum_steps</span>  <span class="c1"># Number of times to step the optimizer</span>

<span class="n">ckpt_dir</span> <span class="o">=</span> <span class="n">config</span><span class="o">.</span><span class="n">ckpt_dir</span>
<span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p><strong>Example calculations for 8 GPUs:</strong></p>
<ul>
<li><code>tokens_per_step = 4  2048  8 = 65,536 tokens/step</code>  </li>
<li><code>tokens_per_opt_step = 65,536  8 = 524,288 tokens/optimizer_step</code>  </li>
<li><code>train_iterations = 45,000,000,000  65,536  686,645 steps</code>  </li>
<li><code>optimization_steps = 686,645  8 = 85,830 optimizer steps</code>  </li>
</ul>
<p>Optimization steps is divided by <code>grad_accum_steps</code> because we only step the optimizer (update parameter) after each round of gradient accumulations. </p>
<hr />
<h2 id="model-and-data-initialization">Model and Data Initialization</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># Instantiate dataset_loader obj</span>
<span class="n">bytes_per_token</span> <span class="o">=</span> <span class="mi">2</span>  <span class="c1"># 2 byte per token (Assuming using uint16)</span>
<span class="n">dataset_loader</span> <span class="o">=</span> <span class="n">DatasetLoader</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">seq_len</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span> <span class="n">process_rank</span><span class="o">=</span><span class="n">ddp_rank</span><span class="p">,</span>
                               <span class="n">num_processes</span><span class="o">=</span><span class="n">ddp_world_size</span><span class="p">,</span> <span class="n">dataset_dir</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">dataset_dir</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
<span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="n">dataset_loader</span><span class="o">.</span><span class="n">print_ds_info</span><span class="p">(</span><span class="n">bytes_per_token</span><span class="o">=</span><span class="n">bytes_per_token</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dataset_loader</span><span class="o">.</span><span class="n">file_idx</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dataset_loader</span><span class="o">.</span><span class="n">tok_idx</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>


<span class="c1"># Load in pretrained tokenizer</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="o">.</span><span class="n">from_file</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">tokenizer_path</span><span class="p">)</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">unk_token</span> <span class="o">=</span> <span class="s2">&quot;&lt;UNK&gt;&quot;</span>  <span class="c1"># Set unknown token to &lt;UNK&gt;</span>
<span class="n">tokenizer</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoders</span><span class="o">.</span><span class="n">ByteLevel</span><span class="p">()</span>  <span class="c1"># For byte-level decoding</span>


<span class="c1"># Create model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">LLaMaTransformer</span><span class="p">(</span>
    <span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span>
    <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
<span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</code></pre></div>
<p>The dataset loader handles sharding across multiple GPUs and streams data from disk to handle large datasets. </p>
<p>The 1.3B param model is initialized primarily with: </p>
<ul>
<li>24 transformer layers  </li>
<li>2048 embedding dimension  </li>
<li>32 attention heads (64-dim each)  </li>
<li>RoPE positional embeddings  </li>
<li>SwiGLU activation functions  </li>
</ul>
<hr />
<h2 id="optimizer-and-scheduler-setup">Optimizer and Scheduler Setup</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># Betas, weight decay, and scheduler follows the LLaMa paper, with the exception of the learning rate</span>
<span class="c1"># Used fused operations if available, from Dr. Karpathy&#39;s video</span>
<span class="n">fused_available</span> <span class="o">=</span> <span class="s1">&#39;fused&#39;</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span>
<span class="n">use_fused</span> <span class="o">=</span> <span class="n">fused_available</span> <span class="ow">and</span> <span class="p">(</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">or</span> <span class="n">ddp</span><span class="p">)</span>
<span class="n">extra_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">fused</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="k">if</span> <span class="n">use_fused</span> <span class="k">else</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">AdamW</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">max_lr</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="n">beta1</span><span class="p">,</span> <span class="n">beta2</span><span class="p">),</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_args</span><span class="p">)</span>
<span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using fused optimizer: </span><span class="si">{</span><span class="n">use_fused</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Instantiating CE Loss and scheduler</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">Scheduler</span><span class="p">(</span><span class="n">torch_optimizer</span><span class="o">=</span><span class="n">optimizer</span><span class="p">,</span>
                      <span class="n">schedule</span><span class="o">=</span><span class="s2">&quot;cosine&quot;</span><span class="p">,</span>
                      <span class="n">training_steps</span><span class="o">=</span><span class="n">optimization_steps</span><span class="p">,</span>
                      <span class="n">warmup_steps</span><span class="o">=</span><span class="n">warmup_iterations</span><span class="p">,</span>
                      <span class="n">max_lr</span><span class="o">=</span><span class="n">max_lr</span><span class="p">,</span>
                      <span class="n">min_lr</span><span class="o">=</span><span class="n">min_lr</span><span class="p">)</span>
</code></pre></div>
<p><strong>In this section:</strong></p>
<ul>
<li>Check if AdamW supports fused kernels for better performance before instantiation</li>
<li>Create the Criterion (using CrossEntropyLoss which is typical when training LLMs)</li>
<li>Create a (custom) scheduler based on cosine learning rate schedule with warmup  </li>
</ul>
<hr />
<h2 id="checkpoint-loading">Checkpoint Loading</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># prev_tok_trained would be how many tokens the model has already been trained (for loading in models, if applicable)</span>
<span class="n">prev_tok_trained</span> <span class="o">=</span> <span class="mi">0</span>

<span class="c1"># Loading in checkpoint to resume training if needed</span>
<span class="k">if</span> <span class="n">load_ckpt</span><span class="p">:</span>
    <span class="n">ckpt_dict</span><span class="p">,</span> <span class="n">prev_tok_trained</span> <span class="o">=</span> <span class="n">load_checkpoint</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">ckpt_dir</span><span class="o">=</span><span class="n">ckpt_dir</span><span class="p">,</span> <span class="n">ddp</span><span class="o">=</span><span class="n">ddp</span><span class="p">,</span> <span class="n">master_process</span><span class="o">=</span><span class="n">master_process</span><span class="p">)</span>

    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;model_state_dict&quot;</span><span class="p">])</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">])</span>

    <span class="c1"># Manually check the scheduler here, T_max and eta_min should match, if not, can lead to undefined behaviors</span>
    <span class="k">if</span> <span class="n">use_prev_scheduler</span><span class="p">:</span>
        <span class="k">assert</span> <span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;max_lr&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">max_lr</span>
        <span class="k">assert</span> <span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;min_lr&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">min_lr</span>
        <span class="k">assert</span> <span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;train_iterations&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">train_iterations</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;scheduler_state_dict&quot;</span><span class="p">])</span>

        <span class="n">dataset_loader</span><span class="o">.</span><span class="n">file_idx</span> <span class="o">=</span> <span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;file_idx&quot;</span><span class="p">]</span>
        <span class="n">dataset_loader</span><span class="o">.</span><span class="n">tok_idx</span> <span class="o">=</span> <span class="n">ckpt_dict</span><span class="p">[</span><span class="s2">&quot;tok_idx&quot;</span><span class="p">]</span>
        <span class="n">dataset_loader</span><span class="o">.</span><span class="n">file_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">dataset_loader</span><span class="o">.</span><span class="n">filepaths</span><span class="p">[</span><span class="n">dataset_loader</span><span class="o">.</span><span class="n">file_idx</span><span class="p">])</span>
</code></pre></div>
<p>For checkpoint restoration, this would need to load in the model and optimizer state dicts, and if desired, continue exactly from where the previous run left off at. </p>
<hr />
<h2 id="model-compilation-and-ddp-wrapping">Model Compilation and DDP Wrapping</h2>
<div class="highlight"><pre><span></span><code><span class="c1"># Compiling the model via torch.compile reduces the training time</span>
<span class="c1"># Though may not be compatible with certain GPUs. If so, turn &quot;compile_model&quot; in config to False</span>
<span class="k">if</span> <span class="n">enable_compilation</span> <span class="ow">and</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="c1"># Interestingly enough, DDP docs recommends applying ddp wrapper before compiling</span>
    <span class="c1"># Karpathy&#39;s implementation is the other way around, compile -&gt; ddp wrapper</span>
    <span class="n">model_handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">ddp_rank</span><span class="p">]))</span>
<span class="k">elif</span> <span class="n">enable_compilation</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">model_handle</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="k">elif</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">model_handle</span> <span class="o">=</span> <span class="n">DDP</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">ddp_rank</span><span class="p">])</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">model_handle</span> <span class="o">=</span> <span class="n">model</span>  <span class="c1"># Plain case, not recommended for actual usage</span>
</code></pre></div>
<p>Notice that no matter if we compile, apply DDP, do both or do none, the resulting model will be called <code>model_handle</code>. 
That's because when we need to checkpoint the model, we need the underlying model itself, not the wrapped DDP/Compiled version, and so this deals with separation of concerns.</p>
<p><strong>Important note about compilation order:</strong></p>
<ul>
<li>Current code uses <code>torch.compile(DDP(model))</code> which follows DDP documentation  </li>
<li>Some implementations use <code>DDP(torch.compile(model))</code>  both have tradeoffs  </li>
</ul>
<hr />
<h2 id="training-loop-initialization">Training Loop Initialization</h2>
<div class="highlight"><pre><span></span><code><span class="n">total_tok_trained</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Keeping track of total current tokens that has been processed</span>
<span class="n">next_token_ckpt</span> <span class="o">=</span> <span class="n">token_ckpt</span>

<span class="n">eos_token</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&quot;&lt;EOS&gt;&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">ids</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">all_losses</span> <span class="o">=</span> <span class="p">[]</span>  <span class="c1"># Keeping track of all losses</span>
<span class="n">save_ckpt</span> <span class="o">=</span> <span class="p">{}</span>  <span class="c1"># Used to save model checkpoint (Holds all state_dicts, hyperparameters, etc.)</span>
<span class="n">norm</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>  <span class="c1"># A temp placeholder for actual norm</span>

<span class="c1"># This autocasts certain parts of the layers (mostly matmul portion) within the model to bf16 for faster training</span>
<span class="n">use_amp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="p">(</span><span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">or</span> <span class="n">ddp</span><span class="p">)</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_bf16_supported</span><span class="p">()</span>
<span class="k">if</span> <span class="n">master_process</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Using auto mixed precision: </span><span class="si">{</span><span class="n">use_amp</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div>
<p><strong>Tracking variables:</strong></p>
<ul>
<li><code>total_tok_trained</code>: Counts tokens processed in current run  </li>
<li><code>next_token_ckpt</code>: Token count for next checkpoint save  </li>
<li><code>all_losses</code>: History for checkpoint naming and analysis  </li>
</ul>
<hr />
<h2 id="main-training-loop">Main Training Loop</h2>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_iterations</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">()</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="s2">&quot;cuda&quot;</span> <span class="k">if</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">in</span> <span class="n">device</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">use_amp</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model_handle</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">))</span>
</code></pre></div>
<p>Each iteration begins by fetching a batch of input and target sequences, here shaped <code>(4, 2048)</code>, based on the configuration. 
The forward pass is run inside a <code>torch.autocast</code> context, which enables mixed-precision execution (BF16 where available) to improve speed and memory efficiency. 
The model outputs predictions of shape <code>(B, T, C)</code>, which are then compared against the targets using cross-entropy loss. This loss measures how well the models predicted distributions align with the true next tokens across all sequence positions.</p>
<hr />
<h2 id="gradient-accumulation-and-backward-pass">Gradient Accumulation and Backward Pass</h2>
<div class="highlight"><pre><span></span><code>    <span class="n">train_loss_value</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
    <span class="n">loss</span> <span class="o">/=</span> <span class="n">grad_accum_steps</span>

    <span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
        <span class="n">model_handle</span><span class="o">.</span><span class="n">require_backward_grad_sync</span> <span class="o">=</span> <span class="p">(</span><span class="n">step</span> <span class="o">%</span> <span class="n">grad_accum_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="n">total_tok_trained</span> <span class="o">+=</span> <span class="n">tokens_per_step</span>
    <span class="n">all_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_loss_value</span><span class="p">)</span>
</code></pre></div>
<p>The computed loss is divided by the number of accumulation steps so that gradients average correctly across multiple smaller batches. 
In distributed setups, gradient synchronization is deferred until the end of an accumulation cycle (<code>step % grad_accum_steps == 0</code>) to reduce communication overhead. 
The backward pass then contributes gradients to parameters, while counters track total tokens processed and log raw loss values. This strategy allows training with effectively large batch sizes even on limited GPU memory, while keeping updates consistent across devices.</p>
<hr />
<h2 id="optimizer-step">Optimizer Step</h2>
<div class="highlight"><pre><span></span><code>    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">grad_accum_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">step</span> <span class="o">//</span> <span class="n">grad_accum_steps</span><span class="p">)</span>
        <span class="n">norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">(</span><span class="n">set_to_none</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div>
<p><strong>Optimizer step details:</strong></p>
<ul>
<li>Scheduler steps on optimizer steps, not training steps  </li>
<li>Gradient clipping at 1.0 prevents explosion  </li>
<li><code>set_to_none=True</code> is more memory efficient than zeroing  </li>
</ul>
<hr />
<h2 id="checkpoint-saving">Checkpoint Saving</h2>
<div class="highlight"><pre><span></span><code>    <span class="k">if</span> <span class="p">(</span><span class="n">total_tok_trained</span> <span class="o">&gt;</span> <span class="n">next_token_ckpt</span> <span class="ow">or</span> <span class="n">step</span> <span class="o">==</span> <span class="n">train_iterations</span><span class="p">)</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="n">next_token_ckpt</span> <span class="o">+=</span> <span class="n">token_ckpt</span>

        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;config&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">config</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;model_state_dict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;optimizer_state_dict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;scheduler_state_dict&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;max_lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">max_lr</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;min_lr&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">min_lr</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;train_iterations&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_iterations</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;total_tok_trained&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">total_tok_trained</span> <span class="o">+</span> <span class="n">prev_tok_trained</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;file_idx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">file_idx</span>
        <span class="n">save_ckpt</span><span class="p">[</span><span class="s2">&quot;tok_idx&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">tok_idx</span>

        <span class="n">n</span> <span class="o">=</span> <span class="mi">2500</span>
        <span class="n">avg_loss</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="nb">sum</span><span class="p">(</span><span class="n">all_losses</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="p">:])</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_losses</span><span class="p">[</span><span class="o">-</span><span class="n">n</span><span class="p">:]))</span> <span class="o">*</span> <span class="mi">1000</span><span class="p">)</span>
        <span class="n">combined_tokens</span> <span class="o">=</span> <span class="n">total_tok_trained</span> <span class="o">+</span> <span class="n">prev_tok_trained</span>
        <span class="k">if</span> <span class="n">combined_tokens</span> <span class="o">&lt;</span> <span class="mf">1e10</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_ckpt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ckpt_dir</span><span class="si">}</span><span class="s2">/model_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">combined_tokens</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e6</span><span class="p">)</span><span class="si">}</span><span class="s2">M_</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">}</span><span class="s2">L_</span><span class="si">{</span><span class="n">max_seq_len</span><span class="si">}</span><span class="s2">MSQ.pth&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">save_ckpt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ckpt_dir</span><span class="si">}</span><span class="s2">/model_</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">combined_tokens</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="mf">1e9</span><span class="p">)</span><span class="si">}</span><span class="s2">B_</span><span class="si">{</span><span class="n">avg_loss</span><span class="si">}</span><span class="s2">L_</span><span class="si">{</span><span class="n">max_seq_len</span><span class="si">}</span><span class="s2">MSQ.pth&quot;</span><span class="p">)</span>
</code></pre></div>
<p>At every <code>token_ckpt</code> token interval (or at the very last step of the training run), save a copy of the state at that point. 
Then calculate the average loss in the past <code>n</code> steps which would be used to name the checkpoint file in conjunction with training tokens.</p>
<hr />
<h2 id="evaluation-and-logging">Evaluation and Logging</h2>
<div class="highlight"><pre><span></span><code>    <span class="k">if</span> <span class="n">step</span> <span class="o">%</span> <span class="n">eval_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">master_process</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="ow">and</span> <span class="n">device</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span><span class="p">()</span>

        <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start</span>
        <span class="n">current_lr</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">param_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;lr&quot;</span><span class="p">]</span>
        <span class="n">tokens_processed</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">total_tok_trained</span> <span class="o">//</span> <span class="mf">1e6</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">log_file</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">write_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">step</span><span class="p">,</span> <span class="nb">round</span><span class="p">((</span><span class="n">step</span> <span class="o">/</span> <span class="n">train_iterations</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">train_loss_value</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> 
                         <span class="nb">round</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">e</span> <span class="o">**</span> <span class="n">train_loss_value</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">current_lr</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="nb">round</span><span class="p">(</span><span class="n">norm</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">),</span>
                         <span class="n">tokens_processed</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="n">prev_tok_trained</span> <span class="o">//</span> <span class="mf">1e6</span><span class="p">)</span> <span class="o">+</span> <span class="n">tokens_processed</span><span class="p">,</span>
                         <span class="nb">int</span><span class="p">((</span><span class="n">eval_interval</span> <span class="o">*</span> <span class="n">tokens_per_step</span><span class="p">)</span> <span class="o">//</span> <span class="n">elapsed</span><span class="p">),</span> <span class="nb">int</span><span class="p">(</span><span class="n">elapsed</span><span class="p">)]</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;,&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="nb">str</span><span class="p">(</span><span class="n">wd</span><span class="p">)</span> <span class="k">for</span> <span class="n">wd</span> <span class="ow">in</span> <span class="n">write_data</span><span class="p">]))</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Step: </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> steps   |   Training Progress: </span><span class="si">{</span><span class="p">(</span><span class="n">step</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">train_iterations</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%   |   &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Training Loss: </span><span class="si">{</span><span class="n">train_loss_value</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">   |   Perplexity: </span><span class="si">{</span><span class="n">math</span><span class="o">.</span><span class="n">e</span><span class="w"> </span><span class="o">**</span><span class="w"> </span><span class="n">train_loss_value</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">   |   &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Learning Rate: </span><span class="si">{</span><span class="n">current_lr</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">   |   Norm: </span><span class="si">{</span><span class="n">norm</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">   |   &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;Tokens Processed: </span><span class="si">{</span><span class="n">tokens_processed</span><span class="si">}</span><span class="s2">M (</span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">prev_tok_trained</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="mf">1e6</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">tokens_processed</span><span class="si">}</span><span class="s2">M)   |   &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;tok/s: </span><span class="si">{</span><span class="nb">int</span><span class="p">((</span><span class="n">eval_interval</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tokens_per_step</span><span class="p">)</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">elapsed</span><span class="p">)</span><span class="si">}</span><span class="s2">   |   Time: </span><span class="si">{</span><span class="nb">int</span><span class="p">(</span><span class="n">elapsed</span><span class="p">)</span><span class="si">}</span><span class="s2">s&quot;</span><span class="p">)</span>

        <span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
</code></pre></div>
<p>At regular intervals, the training script logs key metrics to both console and file. 
These include training progress, loss, and perplexity (computed as <code>exp(loss)</code> for easier interpretation), along with learning rate, gradient norm, and tokens processed. 
Token throughput (<code>tok/s</code>) is also tracked to measure efficiency. 
Synchronizing CUDA before timing ensures accurate elapsed measurements, making these logs a reliable snapshot of both training stability and performance.</p>
<hr />
<h2 id="text-generation-samples">Text Generation Samples</h2>
<div class="highlight"><pre><span></span><code>        <span class="k">if</span> <span class="s1">&#39;next_gen_step&#39;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="nb">locals</span><span class="p">():</span>
            <span class="n">next_gen_step</span> <span class="o">=</span> <span class="n">step</span>

        <span class="k">if</span> <span class="n">step</span> <span class="o">&gt;=</span> <span class="n">next_gen_step</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">few_shot_prompts</span><span class="p">),</span> <span class="mi">64</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">eos_token</span><span class="o">=</span><span class="n">eos_token</span><span class="p">))</span>
            <span class="n">next_gen_step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">step</span> <span class="o">*</span> <span class="n">model_gen_multiplier</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Sampled generation at </span><span class="si">{</span><span class="n">step</span><span class="si">=}</span><span class="s2">, next at </span><span class="si">{</span><span class="n">next_gen_step</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;----------------&quot;</span><span class="p">)</span>
</code></pre></div>
<p>In addition to numeric metrics, the model is periodically prompted to generate text from a random few-shot example. 
The interval between generations grows exponentially and the check helps confirm that the model is learning to produce structured, human-like outputs.</p>
<hr />
<h2 id="cleanup">Cleanup</h2>
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="n">ddp</span><span class="p">:</span>
    <span class="n">destroy_process_group</span><span class="p">()</span>
</code></pre></div>
<p><strong>Final step:</strong></p>
<ul>
<li>Properly shuts down distributed process group  </li>
<li>Ensures clean exit and resource release  </li>
</ul>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../../..", "features": ["content.math"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>