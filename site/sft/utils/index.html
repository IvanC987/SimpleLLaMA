
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../prompt_formatting/">
      
      
        <link rel="next" href="../finetuning/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.18">
    
    
      
        <title>Utilities - SimpleLLaMA Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#utilities-for-sft" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="SimpleLLaMA Documentation" class="md-header__button md-logo" aria-label="SimpleLLaMA Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            SimpleLLaMA Documentation
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Utilities
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="SimpleLLaMA Documentation" class="md-nav__button md-logo" aria-label="SimpleLLaMA Documentation" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    SimpleLLaMA Documentation
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Pretraining
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Pretraining
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset Preparation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Tokenization
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Tokenization
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/tokenization/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/tokenization/algorithms/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Algorithms
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/tokenization/examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/tokenization/project/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Project Usage
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Model Architecture
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Model Architecture
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/embeddings/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Embeddings
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/attention/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Attention
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/normalization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Normalization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/feedforward/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    FeedForward
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/decoder_block/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Layer Block
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/model_architecture/end_to_end/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    End To End
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training Process (Beginner)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Training Process (Beginner)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_beginner/introduction/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Introduction
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_beginner/model_config/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Model Configurations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_beginner/dataset_and_batching/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset and Batching
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_beginner/scheduler/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Scheduler
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_beginner/training_loop/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Training Loop
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Training Process (Advanced)
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            Training Process (Advanced)
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/recap/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Basics Recap
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/optimizers/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Optimizer Details
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/loss_function/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Cross Entropy Loss
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/gradient_accumulation/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Gradient Accumulation
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/ddp/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Distributed Data Parallel
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/throughput_optimizations/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Throughput Optimizations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/ckpt_and_eval/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Checkpointing and Evaluations
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pretraining/training_advanced/final_walkthrough/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Final Walkthrough
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Supervised Fine-Tuning
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Supervised Fine-Tuning
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dataset/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Dataset
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../prompt_formatting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Prompt Formatting
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Utilities
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Utilities
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tokenize-and-pad-data" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenize and Pad Data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenize and Pad Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-tokenization-and-padding" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Tokenization and Padding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-validation-check" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Validation Check
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-return-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Return Tensors
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Model Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-evaluation-path" class="md-nav__link">
    <span class="md-ellipsis">
      Full Evaluation Path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#single-batch-evaluation-path" class="md-nav__link">
    <span class="md-ellipsis">
      Single-Batch Evaluation Path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#usage-context" class="md-nav__link">
    <span class="md-ellipsis">
      Usage Context
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetuning/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Finetuning Process
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    RLHF
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            RLHF
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rlhf/overview/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../rlhf/methods/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Methods
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
        
          
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Misc
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Misc
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../misc/benchmarking/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Benchmarking
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../misc/inference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Inference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../misc/notes/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Notes
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
        
          
          <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Custom Training
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_6">
            <span class="md-nav__icon md-icon"></span>
            Custom Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../custom_training/pretraining/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Pretraining
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../custom_training/sft/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Supervised Fine Tuning
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../custom_training/rlhf/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    RLHF
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#tokenize-and-pad-data" class="md-nav__link">
    <span class="md-ellipsis">
      Tokenize and Pad Data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Tokenize and Pad Data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-1-tokenization-and-padding" class="md-nav__link">
    <span class="md-ellipsis">
      Step 1: Tokenization and Padding
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-validation-check" class="md-nav__link">
    <span class="md-ellipsis">
      Step 2: Validation Check
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-return-tensors" class="md-nav__link">
    <span class="md-ellipsis">
      Step 3: Return Tensors
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-evaluation" class="md-nav__link">
    <span class="md-ellipsis">
      Model Evaluation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Model Evaluation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#full-evaluation-path" class="md-nav__link">
    <span class="md-ellipsis">
      Full Evaluation Path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#single-batch-evaluation-path" class="md-nav__link">
    <span class="md-ellipsis">
      Single-Batch Evaluation Path
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#usage-context" class="md-nav__link">
    <span class="md-ellipsis">
      Usage Context
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="utilities-for-sft">Utilities for SFT</h1>
<h2 id="tokenize-and-pad-data">Tokenize and Pad Data</h2>
<p>The next step after formatting the training examples is the transformation of raw <code>(x, y)</code> string pairs into properly padded tensors. In this project, the function <code>tokenize_and_pad_data</code> is responsible for doing exactly that.  </p>
<p>At first glance, the function may look overwhelming: it includes several layers of tokenization, checks, and padding strategies. But once broken down into its main stages, the logic becomes much clearer.  </p>
<p>Let’s start by looking at the function signature and its purpose:  </p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">tokenize_and_pad_data</span><span class="p">(</span><span class="n">batch</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">tuple</span><span class="p">],</span> <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span> <span class="n">pad_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tokenizes and pads a batch of (x, y) training pairs for SFT.</span>

<span class="sd">    Each element in `batch` is a tuple:</span>
<span class="sd">        - x: full prompt including template, user queries, and assistant responses</span>
<span class="sd">        - y: only the final assistant response to supervise with loss</span>

<span class="sd">    The x sequence is right-truncated to `max_seq_len`.</span>
<span class="sd">    The y sequence is left-padded so it aligns with the end of x.</span>
<span class="sd">    Left-padded values in y are filled with `pad_id` and are ignored in loss via `ignore_index`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
</code></pre></div>
<p>At its core, the function takes in a list of <code>(x, y)</code> examples (batch)  where:  </p>
<ul>
<li><code>x</code> is the <strong>full formatted training prompt</strong> (system + user + assistant conversation).  </li>
<li><code>y</code> is the <strong>target assistant response only</strong> (with <code>&lt;EOA&gt;</code> at the end).  </li>
</ul>
<p>It also takes in the tokenizer, to convert the x-y strings into token ids, pad_id corresponds to the token id for a pad token, <code>max_seq_len</code>, the hyper parameter that controls the maximum sequence length allowed, dynamic is a bool meaning if to dynamically pad based on longest example or all up to max_seq_len, device is usually cpu or cuda
Don't worry too much about the other inputs for now, just note the most important inputs is the batch, tokenizer, pad_id and max_seq_len
Further details below. </p>
<p>The goal is to produce two tensors:  </p>
<ol>
<li><code>x_tensor</code>: tokenized, padded input prompts.  </li>
<li><code>y_tensor</code>: tokenized, padded targets aligned to <code>x</code>, where padding positions are filled with <code>pad_id</code> so the loss function ignores them.  </li>
</ol>
<hr />
<h3 id="step-1-tokenization-and-padding">Step 1: Tokenization and Padding</h3>
<div class="highlight"><pre><span></span><code><span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Given batch data should not be empty!&quot;</span>

<span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
<span class="n">max_len</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Maximum tensor len</span>
<span class="n">exceed_len</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">for</span> <span class="n">example</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">example</span>  <span class="c1"># Unpack values</span>

    <span class="c1"># Tokenize x-y pair</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">ids</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">ids</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_seq_len</span><span class="p">:</span>  <span class="c1"># max_seq_len is inclusive of context, so x shouldn&#39;t be &gt;= that</span>
        <span class="n">exceed_len</span> <span class="o">+=</span> <span class="mi">1</span>
        <span class="k">continue</span>

    <span class="n">max_len</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">x_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>

    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">num_left_pad</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>  <span class="c1"># Need an additional right pad later on for left-shift</span>

    <span class="k">if</span> <span class="n">num_left_pad</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Target response longer than input window. Skipping.&quot;</span><span class="p">)</span>
        <span class="k">continue</span>

    <span class="n">y_left_pad</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">num_left_pad</span><span class="p">,),</span> <span class="n">pad_id</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
    <span class="n">y_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">y_left_pad</span><span class="p">,</span> <span class="n">y</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">))</span>
</code></pre></div>
<p>First, ensure that the given batch is not empty.<br />
Initialize two empty lists, <code>x_data</code> and <code>y_data</code>, which will later hold the two resulting x-y tensors.  </p>
<p>Next, the two variables <code>max_len</code> and <code>exceed_len</code> are initialized. <code>max_len</code> keeps track of the length of the longest sequence of tokens seen in the current batch, while <code>exceed_len</code> records how many training examples surpassed the maximum allowed sequence length.  </p>
<p>Now we iterate through the batch:</p>
<blockquote>
<p><code>for example in batch:</code></p>
</blockquote>
<p>Where each <code>example</code> is the <code>(x, y)</code> string pair.  </p>
<p>Both <code>x</code> and <code>y</code> are transformed into lists of integers, each representing tokens from the vocabulary.  </p>
<p>We now check if the number of tokens in tokenized string <code>x</code> is greater than <code>max_seq_len</code>. If so, we discard that example. Truncation could be done instead, but that’s a separate concern. For now, the goal is to prevent prompts from overflowing the model’s context window. If discarded, increment <code>exceed_len</code> by 1. (Though the naming could be improved, it represents the number of examples that exceeded <code>max_seq_len</code>.)  </p>
<p>If it does not exceed <code>max_seq_len</code>, then continue by updating <code>max_len</code> with:  </p>
<blockquote>
<p><code>max_len = max(max_len, len(x))</code></p>
</blockquote>
<p>Here, <code>max_seq_len</code> refers to the fixed hyperparameter (e.g. 2048 or 4096 tokens), while <code>max_len</code> is the longest sequence of input tokens seen so far in this batch. The former filters out overly long examples, the latter is used to determine how much padding is needed later.  </p>
<p>Then, transform <code>x</code> into a tensor and append it to <code>x_data</code>. This will be the input tensor to the model as one example sequence.  </p>
<p>For <code>y</code>, it’s more nuanced. We cannot simply tokenize and append because we need alignment for the loss function. First, calculate the amount of left padding required, accounting for a shift (<code>-1</code>). Then create a left padding tensor, and concatenate it with <code>y</code>. Finally, append the result to <code>y_data</code>.  </p>
<hr />
<p>Let’s illustrate with a concrete example. Suppose we have an <code>(x, y)</code> pair where:  </p>
<p><strong>x:</strong>  </p>
<div class="highlight"><pre><span></span><code>&lt;SOU&gt;What is 2+2?&lt;EOU&gt;
&lt;SOA&gt;4&lt;EOA&gt;
</code></pre></div>
<p><strong>y:</strong>  </p>
<div class="highlight"><pre><span></span><code>4&lt;EOA&gt;
</code></pre></div>
<p>(We omit the system prompt here for brevity.)  </p>
<p>Tokenized, <code>x</code> might look like:<br />
<code>[4, 4909, 4862, 981, 3172, 981, 2356, 5, 6, 411, 7]</code>  </p>
<p>And <code>y</code>:<br />
<code>[411, 7]</code>  </p>
<p>Here, <code>411</code> corresponds to token “4” and <code>7</code> corresponds to <code>&lt;EOA&gt;</code>. Importantly, <code>y</code> is always the suffix of <code>x</code>.  </p>
<p>For <code>x</code>, we immediately convert it into a tensor and append it to <code>x_data</code>.  </p>
<p>For <code>y</code>, convert to a tensor and compute:  </p>
<p><code>num_left_pad = len(x) - len(y) - 1 = 11 - 2 - 1 = 8</code>  </p>
<p>Then create:  </p>
<p><code>y_left_pad = torch.tensor([2, 2, 2, 2, 2, 2, 2, 2])</code>  </p>
<p>(assuming <code>pad_id = 2</code>).  </p>
<p>Concatenate with <code>y</code>:  </p>
<p><code>torch.tensor([2, 2, 2, 2, 2, 2, 2, 2, 411, 7])</code>  </p>
<p>Append this to <code>y_data</code>.  </p>
<p>Unrolling side by side:  </p>
<div class="highlight"><pre><span></span><code>x: [4, 4909, 4862, 981, 3172, 981, 2356, 5,   6, 411, 7]
y: [2,    2,    2,   2,    2,   2,    2, 2, 411,   7]
</code></pre></div>
<p>Notice that the targets are padding until we hit token id <code>411</code>. This design ensures the model is not trained to predict the system prompt or the user queries — only the assistant’s outputs.  </p>
<p>When the model sees:  </p>
<div class="highlight"><pre><span></span><code>&lt;SOU&gt;What is 2+2?&lt;EOU&gt;
&lt;SOA&gt;
</code></pre></div>
<p>It is expected to predict token <code>411</code> (the number 4). Then, given the sequence with <code>411</code> included:  </p>
<div class="highlight"><pre><span></span><code>&lt;SOU&gt;What is 2+2?&lt;EOU&gt;
&lt;SOA&gt;4
</code></pre></div>
<p>The model should predict <code>&lt;EOA&gt;</code> (<code>7</code>).  </p>
<p>Thus, this remains next-token prediction, but now constrained to assistant responses. Instead of uncontrolled continuation, the model learns structured QA behavior.  </p>
<p>Do note the if conditional block where <code>if num_left_pad &lt; 0</code>, meaning the target response is longer than the input, the example is malformed and skipped. This normally shouldn't occur, since <code>y</code> is expected to be a suffix of <code>x</code>, but added as a safety check. </p>
<hr />
<h3 id="step-2-validation-check">Step 2: Validation Check</h3>
<p>After populating <code>x_data</code> and <code>y_data</code>, the function performs a quick check:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># return x_data, y_data</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;All examples has been skipped due to all chat conversations exceeding </span><span class="si">{</span><span class="n">max_seq_len</span><span class="si">=}</span><span class="s2">&quot;</span>
<span class="k">if</span> <span class="n">exceed_len</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mf">0.1</span><span class="p">:</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="mi">100</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">exceed_len</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">% of examples in this batch has been skipped due to assistant responses exceeding </span><span class="si">{</span><span class="n">max_seq_len</span><span class="si">=}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span> <span class="k">if</span> <span class="n">dynamic</span> <span class="k">else</span> <span class="n">max_seq_len</span>
</code></pre></div>
<p>The first assertion ensures that the dataset did not collapse entirely. If <code>len(x_data)</code> is zero, it means that <em>all</em> of the examples in the batch were skipped, usually because they exceeded the maximum allowed sequence length (<code>max_seq_len</code>). This would be a problematic error, since the model would have no valid training examples to work with, and so the assertion is a necessary safeguard.</p>
<p>The second check introduces a soft warning mechanism. It calculates the ratio of discarded examples (<code>exceed_len / len(batch)</code>) and, if at least 10% of the examples in the batch were rejected, issues a warning. This does not stop execution but serves as a red flag: your dataset or chosen hyperparameters may be suboptimal, and the model could be missing out on significant amounts of training data.</p>
<p>Finally, <code>max_len</code> is updated. If the <code>dynamic</code> flag is set to <code>True</code>, the function uses the maximum length observed in the current batch. This keeps padding minimal, ensuring better efficiency since padding consumes memory and compute without adding training signal. However, if <code>dynamic</code> is <code>False</code>, the function defaults to the global <code>max_seq_len</code>, which ensures all batches are consistently padded to the same fixed length. This option is particularly useful when stress-testing hardware capacity, making sure everything fits into memory.</p>
<hr />
<h3 id="step-3-return-tensors">Step 3: Return Tensors</h3>
<p>Finally, the function decides how to pad <code>x_data</code> and <code>y_data</code> to a consistent length:  </p>
<div class="highlight"><pre><span></span><code><span class="n">x_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),),</span> <span class="n">pad_id</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_data</span>
<span class="p">])</span>

<span class="n">y_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">y</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">),),</span> <span class="n">pad_id</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">y_data</span>
<span class="p">])</span>

<span class="k">assert</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_data</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
<span class="k">return</span> <span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span>
</code></pre></div>
<hr />
<p>Let’s break it down step by step.  </p>
<p><strong>Padding the Input (<code>x_data</code>)</strong>:</p>
<p>At this point, <code>x_data</code> is a list of 1D tensors, each tensor corresponding to the tokenized version of a single input string. Since these strings will almost always be of different lengths, we cannot directly batch them together into a single 2D tensor. PyTorch requires all rows in a tensor to have the same length (no ragged tensors). To fix this, we add <strong>padding tokens</strong> so that every example reaches the same length.  </p>
<p>This line handles it:  </p>
<div class="highlight"><pre><span></span><code><span class="n">torch</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">((</span><span class="n">max_len</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">),),</span> <span class="n">pad_id</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<p>Here,  </p>
<ul>
<li><code>x</code> is the original sequence of token IDs.  </li>
<li><code>torch.full((max_len - len(x),), pad_id, device=device)</code> creates a 1D tensor filled with the padding token ID (<code>pad_id</code>), with just enough elements to extend <code>x</code> to <code>max_len</code>.  </li>
<li><code>torch.concat(...)</code> joins the original sequence <code>x</code> with the padding tensor along the last dimension, effectively extending <code>x</code> to the full <code>max_len</code>.  </li>
</ul>
<p>After this, each input sequence has exactly the same length, ensuring they can all be stacked together.  </p>
<p><strong>Padding the Targets (<code>y_data</code>)</strong></p>
<p>The process for <code>y_data</code> is nearly identical. Each target sequence is extended with padding tokens until it also reaches <code>max_len</code>. One subtle difference is that <code>y_data</code> already had <strong>left padding</strong> applied in Step 1 to align assistant responses with the correct positions in the input. This step adds any <strong>right padding</strong> that is still needed so that <code>y_data</code> fully matches the shape of <code>x_data</code>.  </p>
<p>This ensures both <code>x_data</code> and <code>y_data</code> align perfectly in shape, with every row corresponding to one example in the batch.  </p>
<p><strong>Stacking into Final Tensors</strong></p>
<p>Finally, both padded lists are wrapped in <code>torch.stack([...])</code>.<br />
This function takes a list of tensors of identical shape and combines them into a single tensor by adding a new leading dimension. In this case, that leading dimension corresponds to the <strong>batch size</strong>.  </p>
<ul>
<li>After stacking, <code>x_data</code> has shape <code>(batch_size, max_len)</code>.  </li>
<li>Similarly, <code>y_data</code> has shape <code>(batch_size, max_len)</code>.  </li>
</ul>
<p>This step transforms our batch from a <em>list of variable-length tensors</em> into two consistent 2D tensors ready for model training.  </p>
<p>Before returning, the function runs two assertions:  </p>
<div class="highlight"><pre><span></span><code><span class="k">assert</span> <span class="n">x_data</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">y_data</span><span class="o">.</span><span class="n">shape</span>
<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span>
</code></pre></div>
<p>To make sure that inputs and targets are aligned and that the final tensors are indeed two-dimensional, with one axis for the batch and one for the sequence length.  </p>
<p>If either check fails, it indicates a problem in preprocessing that must be fixed before training continues.</p>
<p>The function then returns the pair <code>(x_data, y_data)</code>, now guaranteed to be properly padded, aligned, and in a form suitable for direct use in the model’s forward pass.  </p>
<hr />
<h2 id="model-evaluation">Model Evaluation</h2>
<p>The <code>eval_model</code> function provides the evaluation mechanism for measuring how well the model performs in generating assistant responses to user inputs during supervised fine-tuning. Here's the function signature: </p>
<div class="highlight"><pre><span></span><code><span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">eval_model</span><span class="p">(</span><span class="n">model</span><span class="p">:</span> <span class="n">LLaMaTransformer</span><span class="p">,</span>
               <span class="n">criterion</span><span class="p">:</span> <span class="n">CrossEntropyLoss</span><span class="p">,</span>
               <span class="n">tokenizer</span><span class="p">:</span> <span class="n">Tokenizer</span><span class="p">,</span>
               <span class="n">dataset_loader</span><span class="p">:</span> <span class="n">JSONDatasetLoader</span><span class="p">,</span>
               <span class="n">use_amp</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
               <span class="n">full_eval</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
               <span class="n">pad_id</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">max_seq_len</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
               <span class="n">dynamic</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
               <span class="n">device</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
</code></pre></div>
<p>The <code>@torch.no_grad()</code> decorator is used so that gradients are not tracked during evaluation. This reduces computational overhead since we are not performing backpropagation (so gradients aren't needed).</p>
<h3 id="parameters">Parameters</h3>
<ul>
<li><strong>model</strong>: The model that's currently undergoing fine-tuning.</li>
<li><strong>criterion</strong>: The loss function (<code>CrossEntropyLoss</code>) used to measure prediction error.</li>
<li><strong>tokenizer</strong>: Tokenizer used to encode text into token IDs.</li>
<li><strong>dataset_loader</strong>: Instance of <code>JSONDatasetLoader</code> that manages training and validation data.</li>
<li><strong>use_amp</strong>: Boolean controlling automatic mixed precision (BF16 or FP32) for performance optimization.</li>
<li><strong>full_eval</strong>: Determines whether to evaluate the entire validation set or a single batch.</li>
<li><strong>pad_id</strong>: Token ID used for padding, ignored by the loss function.</li>
<li><strong>max_seq_len</strong>: Maximum allowable sequence length.</li>
<li><strong>dynamic</strong>: Whether to use dynamic padding (based on longest sequence in batch) or fixed padding.</li>
<li><strong>device</strong>: Target device ('cuda' or 'cpu').</li>
</ul>
<hr />
<h3 id="full-evaluation-path">Full Evaluation Path</h3>
<p>When <code>full_eval=True</code>, the function runs through the <strong>entire validation dataset</strong>, calculating loss across all batches:</p>
<div class="highlight"><pre><span></span><code><span class="k">if</span> <span class="n">full_eval</span><span class="p">:</span>  <span class="c1"># Meaning we want to iterate over the entire validation epoch</span>
    <span class="n">current_val_epoch</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">val_epoch</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="n">current_val_epoch</span> <span class="o">==</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">val_epoch</span><span class="p">:</span>
        <span class="n">batch</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">increment_val_idx</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">tokenize_and_pad_data</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">pad_id</span><span class="o">=</span><span class="n">pad_id</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span>
                                     <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">use_amp</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

            <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">))</span>

        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>

    <span class="k">return</span> <span class="nb">sum</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span>
</code></pre></div>
<p>Here’s what happens step-by-step:</p>
<ol>
<li><strong>Initialize tracking variables:</strong> The function first records the current validation epoch (<code>current_val_epoch</code>) and creates an empty list <code>losses</code> to store batch-level losses.</li>
<li><strong>Iterate through validation data:</strong> It loops until one full validation epoch is processed.</li>
<li><strong>Batch retrieval:</strong> Each batch of validation examples is fetched from the loader.</li>
<li><strong>Tokenization &amp; Padding:</strong> The batch is passed through <code>tokenize_and_pad_data()</code> to ensure uniform tensor sizes.</li>
<li><strong>Forward pass:</strong> The model processes <code>x</code> under mixed precision, outputting logits of shape <code>(batch, seq_len, vocab_size)</code>.</li>
<li><strong>Loss computation:</strong> The predictions and labels are reshaped into 2D matrices, and cross-entropy loss is computed.</li>
<li><strong>Aggregation:</strong> Each batch loss is appended to the list, and finally, the average loss across all batches is returned.</li>
</ol>
<p>This mode is used at the <strong>end of each epoch</strong> to measure the model’s complete validation performance.</p>
<hr />
<h3 id="single-batch-evaluation-path">Single-Batch Evaluation Path</h3>
<p>When <code>full_eval=False</code>, only a <strong>single batch</strong> of validation data is evaluated. This is used for quick checks during training, at evaluation intervals:</p>
<div class="highlight"><pre><span></span><code><span class="k">else</span><span class="p">:</span>  <span class="c1"># Just want a single evaluation</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="n">dataset_loader</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">train</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">increment_val_idx</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">tokenize_and_pad_data</span><span class="p">(</span><span class="n">batch</span><span class="o">=</span><span class="n">batch</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">pad_id</span><span class="o">=</span><span class="n">pad_id</span><span class="p">,</span> <span class="n">max_seq_len</span><span class="o">=</span><span class="n">max_seq_len</span><span class="p">,</span>
                                 <span class="n">dynamic</span><span class="o">=</span><span class="n">dynamic</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">autocast</span><span class="p">(</span><span class="n">device_type</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span> <span class="k">if</span> <span class="n">use_amp</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">):</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">B</span><span class="p">,</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">,</span> <span class="n">C</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">B</span> <span class="o">*</span> <span class="n">T</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</code></pre></div>
<p>This version skips looping and calculates the loss for a single batch. It is far faster and is typically used to monitor progress during training — allowing the user to see whether the loss is trending downward.</p>
<hr />
<h3 id="usage-context">Usage Context</h3>
<p>During fine-tuning, <code>eval_model()</code> is called repeatedly:</p>
<ul>
<li><strong>Full evaluation:</strong> Once per epoch to get the complete validation loss.</li>
<li><strong>Single-batch evaluation:</strong> At regular intervals (e.g., every few hundred optimizer steps) for quick feedback.</li>
</ul>
<p>This provides a balance between <strong>speed</strong> and <strong>accuracy</strong> in tracking model performance. Over time, decreasing validation loss (and its corresponding perplexity) signals effective alignment and improved response generation behavior.</p>
<hr />












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["content.math"], "search": "../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.92b07e13.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>